{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# TODOs\n# (1) Evaluate the topic models ✅️\n# (2) Try to calculate sentence similarity\n# (3) Create a new model that took the topic models and sentence similarity to create prediction\n# (4) Automate them all","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup cuML\n\"\"\"\nimport sys\n!cp ../input/rapids/rapids.21.06 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path += [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"]\nsys.path += [\"/opt/conda/envs/rapids/lib/python3.7\"]\nsys.path += [\"/opt/conda/envs/rapids/lib\"]\n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-10-27T10:09:01.503229Z","iopub.execute_input":"2022-10-27T10:09:01.503836Z","iopub.status.idle":"2022-10-27T10:10:58.301319Z","shell.execute_reply.started":"2022-10-27T10:09:01.503785Z","shell.execute_reply":"2022-10-27T10:10:58.299814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:25:40.170018Z","iopub.execute_input":"2022-10-27T13:25:40.170440Z","iopub.status.idle":"2022-10-27T13:25:41.504894Z","shell.execute_reply.started":"2022-10-27T13:25:40.170402Z","shell.execute_reply":"2022-10-27T13:25:41.503354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet bertopic\n# !pip install --quiet sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2022-10-29T05:44:09.676681Z","iopub.execute_input":"2022-10-29T05:44:09.677130Z","iopub.status.idle":"2022-10-29T05:46:04.059396Z","shell.execute_reply.started":"2022-10-29T05:44:09.677090Z","shell.execute_reply":"2022-10-29T05:46:04.057986Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import time\n\nimport pandas as pd","metadata":{"_uuid":"9e75b4f8-39d0-41f2-8a95-3ccf80f059aa","_cell_guid":"7a50e817-da0a-42ee-be79-541eca7105ac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-10-28T03:39:17.341238Z","iopub.execute_input":"2022-10-28T03:39:17.341706Z","iopub.status.idle":"2022-10-28T03:39:17.348762Z","shell.execute_reply.started":"2022-10-28T03:39:17.341661Z","shell.execute_reply":"2022-10-28T03:39:17.347780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from hn_sentence_similarity_utils import load_data, remove_one_word, \\\n                                         remove_job_postings, remove_links, \\\n                                         clean_non_stories, clean_last_word_year_and_pdf, \\\n                                         lemmatize, finalizes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fp = \"../input/hackernews-stories-since-2018/hackernews-stories-since-2018.csv\"\ndf_2018 = load_data(fp)\ndf_2018.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:32:39.660616Z","iopub.execute_input":"2022-10-27T13:32:39.661030Z","iopub.status.idle":"2022-10-27T13:32:55.184809Z","shell.execute_reply.started":"2022-10-27T13:32:39.660987Z","shell.execute_reply":"2022-10-27T13:32:55.183652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_sentences = (df_2018\n                    ['title']\n                    .drop_duplicates()\n                    .pipe(remove_one_word)\n                    .pipe(remove_job_postings)\n                    .pipe(remove_links)\n                    .pipe(clean_non_stories)\n                    .pipe(clean_last_word_year_and_pdf)\n                    .pipe(lemmatize)\n                    .pipe(finalizes)\n).values","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:32:55.186653Z","iopub.execute_input":"2022-10-27T13:32:55.187302Z","iopub.status.idle":"2022-10-27T13:34:07.793266Z","shell.execute_reply.started":"2022-10-27T13:32:55.187252Z","shell.execute_reply":"2022-10-27T13:34:07.792228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_2018","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:34:07.795858Z","iopub.execute_input":"2022-10-27T13:34:07.796247Z","iopub.status.idle":"2022-10-27T13:34:07.880095Z","shell.execute_reply.started":"2022-10-27T13:34:07.796211Z","shell.execute_reply":"2022-10-27T13:34:07.878960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the Embeddings from Sentence Transformer by using GPU\nfrom sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembeddings = model.encode(corpus_sentences, show_progress_bar=True, convert_to_numpy=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:34:17.569184Z","iopub.execute_input":"2022-10-27T13:34:17.569601Z","iopub.status.idle":"2022-10-27T13:40:57.163893Z","shell.execute_reply.started":"2022-10-27T13:34:17.569561Z","shell.execute_reply":"2022-10-27T13:40:57.162797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfn = \"/kaggle/working/sentence-transformer-unnormalized-embeddings.pkl\"\nwith open(fn, \"wb\") as f:\n    pickle.dump({'sentences': corpus_sentences,\n                 'embeddings': embeddings},f)\n\n!du -h $fn","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:40:57.166226Z","iopub.execute_input":"2022-10-27T13:40:57.167094Z","iopub.status.idle":"2022-10-27T13:41:13.094504Z","shell.execute_reply.started":"2022-10-27T13:40:57.167051Z","shell.execute_reply":"2022-10-27T13:41:13.093165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reload embeddings\nimport pickle\nfn = \"/kaggle/working/sentence-transformer-unnormalized-embeddings.pkl\"\nwith open(fn, \"rb\") as f:\n    cached_data = pickle.load(f)\n    corpus_sentences = cached_data['sentences']\n#     embeddings = cached_data['embeddings']","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:39:17.350798Z","iopub.execute_input":"2022-10-28T03:39:17.351217Z","iopub.status.idle":"2022-10-28T03:39:22.017299Z","shell.execute_reply.started":"2022-10-28T03:39:17.351172Z","shell.execute_reply":"2022-10-28T03:39:22.016122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from bertopic import BERTopic\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.decomposition import IncrementalPCA\nfrom bertopic.vectorizers import OnlineCountVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:39:22.020131Z","iopub.execute_input":"2022-10-28T03:39:22.020815Z","iopub.status.idle":"2022-10-28T03:39:45.391185Z","shell.execute_reply.started":"2022-10-28T03:39:22.020774Z","shell.execute_reply":"2022-10-28T03:39:45.390008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batches\numap_model = IncrementalPCA(n_components=200)\ncluster_model = MiniBatchKMeans(n_clusters=300, random_state=0)\nvectorizer_model = OnlineCountVectorizer(stop_words=\"english\", decay=.01)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:40:53.885877Z","iopub.execute_input":"2022-10-28T03:40:53.886301Z","iopub.status.idle":"2022-10-28T03:40:53.892332Z","shell.execute_reply.started":"2022-10-28T03:40:53.886265Z","shell.execute_reply":"2022-10-28T03:40:53.890938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare model\ntopic_model = BERTopic(\n    umap_model=umap_model,\n    hdbscan_model=cluster_model, \n    vectorizer_model=vectorizer_model, \n    n_gram_range=(1, 2),\n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:40:54.226431Z","iopub.execute_input":"2022-10-28T03:40:54.227136Z","iopub.status.idle":"2022-10-28T03:40:54.232768Z","shell.execute_reply.started":"2022-10-28T03:40:54.227098Z","shell.execute_reply":"2022-10-28T03:40:54.231675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split list into N equal length\n# https://stackoverflow.com/a/2135920/8996974\ndef split(a, n):\n    k, m = divmod(len(a), n)\n    return ((i, a[i*k+min(i, m):(i+1)*k+min(i+1, m)]) for i in range(n))","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:40:54.537643Z","iopub.execute_input":"2022-10-28T03:40:54.538676Z","iopub.status.idle":"2022-10-28T03:40:54.545224Z","shell.execute_reply.started":"2022-10-28T03:40:54.538628Z","shell.execute_reply":"2022-10-28T03:40:54.543964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 100K split is processed in 20 minutes! That's too long!!\n# Let's try splitting it to smaller parts instead\nN = 8\ndoc_chunks = split(corpus_sentences, N)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:40:57.725434Z","iopub.execute_input":"2022-10-28T03:40:57.726186Z","iopub.status.idle":"2022-10-28T03:40:57.731185Z","shell.execute_reply.started":"2022-10-28T03:40:57.726149Z","shell.execute_reply":"2022-10-28T03:40:57.730174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topics = []\nfor chunk_no, docs in doc_chunks:\n    print(f\"Processing chunk no: {chunk_no}\")\n    start_time = time.time()\n\n    topic_model.partial_fit(docs)\n    topics.extend(topic_model.topics_)\n\n    print(\"--- {} minutes ---\".format((time.time() - start_time) / 60))\ntopic_model.topics_ = topics","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:41:23.048235Z","iopub.execute_input":"2022-10-28T03:41:23.049016Z","iopub.status.idle":"2022-10-28T03:50:42.424033Z","shell.execute_reply.started":"2022-10-28T03:41:23.048978Z","shell.execute_reply":"2022-10-28T03:50:42.422687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_no = '10'\nmodel_name = '10-lemmatized-BERTopic-ipca90-batchkmean300-8N'\ntopic_model.save(f'/kaggle/working/{model_no}/{model_name}')","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:31:42.603827Z","iopub.execute_input":"2022-10-28T04:31:42.604246Z","iopub.status.idle":"2022-10-28T04:31:49.774906Z","shell.execute_reply.started":"2022-10-28T04:31:42.604198Z","shell.execute_reply":"2022-10-28T04:31:49.773706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Visualizing Results","metadata":{}},{"cell_type":"code","source":"from bertopic import BERTopic\ntopic_model = BERTopic.load('...')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq = topic_model.get_topic_info(); print(freq.to_markdown())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(\n    freq.sort_values('Count', ascending=False)\n        .head(20)\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-27T15:48:09.303020Z","iopub.execute_input":"2022-10-27T15:48:09.305629Z","iopub.status.idle":"2022-10-27T15:48:09.317329Z","shell.execute_reply.started":"2022-10-27T15:48:09.305589Z","shell.execute_reply":"2022-10-27T15:48:09.316306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.get_topic(87)  # Select the most frequent topic","metadata":{"execution":{"iopub.status.busy":"2022-10-27T14:20:17.957901Z","iopub.execute_input":"2022-10-27T14:20:17.958283Z","iopub.status.idle":"2022-10-27T14:20:17.965571Z","shell.execute_reply.started":"2022-10-27T14:20:17.958250Z","shell.execute_reply":"2022-10-27T14:20:17.964541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.topics_[:10]","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:53:41.264349Z","iopub.execute_input":"2022-10-27T13:53:41.265153Z","iopub.status.idle":"2022-10-27T13:53:41.274701Z","shell.execute_reply.started":"2022-10-27T13:53:41.265104Z","shell.execute_reply":"2022-10-27T13:53:41.273613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.visualize_topics()","metadata":{"execution":{"iopub.status.busy":"2022-10-27T14:47:34.187482Z","iopub.execute_input":"2022-10-27T14:47:34.188688Z","iopub.status.idle":"2022-10-27T14:47:52.655767Z","shell.execute_reply.started":"2022-10-27T14:47:34.188648Z","shell.execute_reply":"2022-10-27T14:47:52.654916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.visualize_hierarchy(top_n_topics=100)","metadata":{"execution":{"iopub.status.busy":"2022-10-27T14:47:52.658014Z","iopub.execute_input":"2022-10-27T14:47:52.658659Z","iopub.status.idle":"2022-10-27T14:47:52.999975Z","shell.execute_reply.started":"2022-10-27T14:47:52.658617Z","shell.execute_reply":"2022-10-27T14:47:52.998894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.visualize_barchart(top_n_topics=10)","metadata":{"execution":{"iopub.status.busy":"2022-10-27T14:47:53.001717Z","iopub.execute_input":"2022-10-27T14:47:53.002109Z","iopub.status.idle":"2022-10-27T14:47:53.189370Z","shell.execute_reply.started":"2022-10-27T14:47:53.002073Z","shell.execute_reply":"2022-10-27T14:47:53.188262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.visualize_heatmap(n_clusters=100, width=1000, height=1000)","metadata":{"execution":{"iopub.status.busy":"2022-10-27T13:54:23.905458Z","iopub.execute_input":"2022-10-27T13:54:23.905875Z","iopub.status.idle":"2022-10-27T13:54:24.104255Z","shell.execute_reply.started":"2022-10-27T13:54:23.905835Z","shell.execute_reply":"2022-10-27T13:54:24.103412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = [\n    \"I would like a job writing Haskell\",\n    \"Hybrid recommender systems to improve recommendations for sparse datasets\",\n    \"How poverty changes your mindset\",\n    \"Rust in 2022\",\n    \"PostgreSQL 14\",\n    \"Improved distributed algorithms for fundamental graph problems (2017)\",\n    \"Ask HN: What bits of fundamental knowledge are productivity multipliers?\",\n    \"A first lesson in meta-rationality\",\n    \"Django Newbie Mistakes\",\n    \"Ask HN: Which are the best Go repositories to read to learn the language?\",\n    \"Postgres full-text search: A search engine in a database (2021)\",\n    \"Citybound – A city building game using actor-based distributed simulation\",\n    \"BERTopic: The Future of Topic Modeling\",\n    \"When to use memory safe languages\",\n    \"Being OK with not being extraordinary\",\n    \"TikTok reveals details of how its algorithm works\",\n    \"A general overview of what happens before main() (2019)\",\n    \"Becoming a Centaur\",\n    \"Query serving systems: An emerging category of data systems\",\n    \"Rust – A hard decision pays off \",\n]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:51:03.511853Z","iopub.execute_input":"2022-10-28T03:51:03.512225Z","iopub.status.idle":"2022-10-28T03:51:03.518602Z","shell.execute_reply.started":"2022-10-28T03:51:03.512190Z","shell.execute_reply":"2022-10-28T03:51:03.517389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_sentence = \"Rust – A hard decision pays off \"\nsimilar_topics, similarity = topic_model.find_topics(example_sentence, top_n=5)\nprint(similar_topics)\ntopic_model.get_topic(similar_topics[0])","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:33:11.258244Z","iopub.execute_input":"2022-10-28T04:33:11.259205Z","iopub.status.idle":"2022-10-28T04:33:11.287082Z","shell.execute_reply.started":"2022-10-28T04:33:11.259153Z","shell.execute_reply":"2022-10-28T04:33:11.285788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Figuring Which Model Make Sense","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:36:39.314100Z","iopub.execute_input":"2022-10-28T03:36:39.314565Z","iopub.status.idle":"2022-10-28T03:36:40.344657Z","shell.execute_reply.started":"2022-10-28T03:36:39.314471Z","shell.execute_reply":"2022-10-28T03:36:40.343392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5-lemmatized-BERTopic-ipca30-batchkmean100-8N\n# 6-lemmatized-BERTopic-ipca60-batchkmean200-8N\n# 9-lemmatized-BERTopic-ipca200-batchkmean300-8N","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bertopic import BERTopic\n\ntopic_model = BERTopic.load(f'/kaggle/working/{model_no}/{model_name}')","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:32:55.434141Z","iopub.execute_input":"2022-10-28T04:32:55.434959Z","iopub.status.idle":"2022-10-28T04:32:58.689151Z","shell.execute_reply.started":"2022-10-28T04:32:55.434906Z","shell.execute_reply":"2022-10-28T04:32:58.687688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\ndef _avg_topics(topics):\n    result = {}\n    for (topic, rate) in topics:\n        if topic in result:\n            result[topic] += rate\n            result[topic] /= 2\n            continue\n        result[topic] = rate\n    return result\n\ndef find_topics(sentence):\n    topics = []\n    multiplier = 1\n    rate = .5\n    decay = .1\n    similar_topics, similarity = topic_model.find_topics(sentence, top_n=1)\n    for st in similar_topics:\n        ts = topic_model.get_topic(st)\n        ts = [(t1, t2 * multiplier) for (t1, t2) in ts]\n        topics.extend(ts)\n        multiplier *= rate\n        rate -= decay\n    topics = _avg_topics(topics)\n    return sorted(topics.items(), key=lambda item: item[1], reverse=True)[:10]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:50:57.912094Z","iopub.execute_input":"2022-10-28T03:50:57.912532Z","iopub.status.idle":"2022-10-28T03:50:57.924119Z","shell.execute_reply.started":"2022-10-28T03:50:57.912484Z","shell.execute_reply":"2022-10-28T03:50:57.922988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sample in samples[:5]:\n    print(sample)\n    print(find_topics(sample))\n    print('-------------')","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:51:14.073345Z","iopub.execute_input":"2022-10-28T03:51:14.074039Z","iopub.status.idle":"2022-10-28T03:51:14.161033Z","shell.execute_reply.started":"2022-10-28T03:51:14.074003Z","shell.execute_reply":"2022-10-28T03:51:14.159845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Coherence Score","metadata":{}},{"cell_type":"code","source":"import gensim.corpora as corpora\nfrom gensim.models.coherencemodel import CoherenceModel","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:59:42.284245Z","iopub.execute_input":"2022-10-28T04:59:42.284604Z","iopub.status.idle":"2022-10-28T04:59:43.095540Z","shell.execute_reply.started":"2022-10-28T04:59:42.284580Z","shell.execute_reply":"2022-10-28T04:59:43.094225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model = BERTopic(verbose=True, n_gram_range=(1, 2))\ntopics, _ = topic_model.fit_transform(corpus_sentences)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess Documents\ndocuments = pd.DataFrame({\"Document\": corpus_sentences,\n                          \"ID\": range(len(corpus_sentences)),\n                          \"Topic\": topics})\ndocuments_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\ncleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:55:37.008087Z","iopub.execute_input":"2022-10-28T03:55:37.008511Z","iopub.status.idle":"2022-10-28T03:55:40.659369Z","shell.execute_reply.started":"2022-10-28T03:55:37.008475Z","shell.execute_reply":"2022-10-28T03:55:40.658233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract vectorizer and analyzer from BERTopic\nvectorizer = topic_model.vectorizer_model\nanalyzer = vectorizer.build_analyzer()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:55:45.655665Z","iopub.execute_input":"2022-10-28T03:55:45.656397Z","iopub.status.idle":"2022-10-28T03:55:45.662462Z","shell.execute_reply.started":"2022-10-28T03:55:45.656350Z","shell.execute_reply":"2022-10-28T03:55:45.661304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract features for Topic Coherence evaluation\nwords = vectorizer.get_feature_names()\ntokens = [analyzer(doc) for doc in cleaned_docs]\ndictionary = corpora.Dictionary(tokens)\ncorpus = [dictionary.doc2bow(token) for token in tokens]\ntopic_words = [[words for words, _ in topic_model.get_topic(topic)] \n               for topic in range(len(set(topics))-1)]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T03:55:47.592529Z","iopub.execute_input":"2022-10-28T03:55:47.592948Z","iopub.status.idle":"2022-10-28T03:56:06.042378Z","shell.execute_reply.started":"2022-10-28T03:55:47.592913Z","shell.execute_reply":"2022-10-28T03:56:06.041328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tree \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2022-10-29T03:35:05.508631Z","iopub.execute_input":"2022-10-29T03:35:05.509222Z","iopub.status.idle":"2022-10-29T03:35:06.617480Z","shell.execute_reply.started":"2022-10-29T03:35:05.509110Z","shell.execute_reply":"2022-10-29T03:35:06.616066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nmodel_no = '10'\nfn = f'/kaggle/working/{model_no}/{model_no}-coherence_params.pkl'\n\nwith open(fn, \"wb\") as f:\n    pickle.dump({'topic_words': topic_words,\n                 'tokens': tokens,\n                 'corpus': corpus,\n                 'dictionary': dictionary\n                }\n                ,f)\n    !du -h $fn","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:33:58.446166Z","iopub.execute_input":"2022-10-28T04:33:58.447218Z","iopub.status.idle":"2022-10-28T04:34:04.063923Z","shell.execute_reply.started":"2022-10-28T04:33:58.447179Z","shell.execute_reply":"2022-10-28T04:34:04.062675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Coherence Params (for computing in CPU)","metadata":{}},{"cell_type":"code","source":"# https://stackoverflow.com/a/27737385/8996974\nfrom functools import wraps\nfrom time import time\n\ndef timing(f):\n    @wraps(f)\n    def wrap(*args, **kw):\n        ts = time()\n        result = f(*args, **kw)\n        te = time()\n        print(f\"func: {f.__name__} args: [{args}, {kw}] took: {te-ts:2.4f} sec\")\n        return result\n    return wrap","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:59:27.093039Z","iopub.execute_input":"2022-10-28T04:59:27.093364Z","iopub.status.idle":"2022-10-28T04:59:27.099759Z","shell.execute_reply.started":"2022-10-28T04:59:27.093316Z","shell.execute_reply":"2022-10-28T04:59:27.098635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n@timing\ndef save_coherence_params(model, corpus_sentences):\n    model_no = model[0]\n    full_path = f'/kaggle/working/{model_no}/{model}'\n    \n    # Load model\n    print(f\"\\nLoading model {model_no}\")\n    topic_model = BERTopic.load(full_path)\n\n    # Preprocess Documents\n    print(f\"Preprocessing...\")\n    topics = topic_model.topics_\n    documents = pd.DataFrame({\"Document\": corpus_sentences,\n                              \"ID\": range(len(corpus_sentences)),\n                              \"Topic\": topics})\n    documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n    cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n    \n    # Extract vectorizer and analyzer from BERTopic\n    print(f\"Extracting features...\")\n    vectorizer = topic_model.vectorizer_model\n    analyzer = vectorizer.build_analyzer()\n    \n    # Extract features for Topic Coherence evaluation\n    words = vectorizer.get_feature_names()\n    tokens = [analyzer(doc) for doc in cleaned_docs]\n    dictionary = corpora.Dictionary(tokens)\n    corpus = [dictionary.doc2bow(token) for token in tokens]\n    topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n                   for topic in range(len(set(topics))-1)]\n    \n    print(f\"Saving the coherence_params...\")\n    fn = f'/kaggle/working/{model_no}/{model_no}-coherence_params.pkl'\n    with open(fn, \"wb\") as f:\n        pickle.dump({'topic_words': topic_words,\n                     'tokens': tokens,\n                     'corpus': corpus,\n                     'dictionary': dictionary\n                    }\n                    ,f)\n    print(f\"Done!\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:48:26.912177Z","iopub.execute_input":"2022-10-28T04:48:26.912705Z","iopub.status.idle":"2022-10-28T04:48:26.928071Z","shell.execute_reply.started":"2022-10-28T04:48:26.912663Z","shell.execute_reply":"2022-10-28T04:48:26.926662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [\n    '5-lemmatized-BERTopic-ipca30-batchkmean100-8N',\n    '6-lemmatized-BERTopic-ipca60-batchkmean200-8N',\n    '9-lemmatized-BERTopic-ipca200-batchkmean300-8N',\n]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:59:29.364406Z","iopub.execute_input":"2022-10-28T04:59:29.364735Z","iopub.status.idle":"2022-10-28T04:59:29.370566Z","shell.execute_reply.started":"2022-10-28T04:59:29.364710Z","shell.execute_reply":"2022-10-28T04:59:29.368830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    save_coherence_params(model, corpus_sentences)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:48:55.185490Z","iopub.execute_input":"2022-10-28T04:48:55.185867Z","iopub.status.idle":"2022-10-28T04:50:34.016888Z","shell.execute_reply.started":"2022-10-28T04:48:55.185836Z","shell.execute_reply":"2022-10-28T04:50:34.015608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Using Stored Coherence Params","metadata":{}},{"cell_type":"code","source":"import pickle\n\n@timing\ndef evaluate_coherence_scores(model):\n    model_no = model.split('-')[0]\n    full_path = f'/kaggle/working/{model_no}/{model_no}-coherence_params.pkl'\n    \n    print(f\"\\nLoading coherence params for model {model_no}\")\n    with open(full_path, \"rb\") as f:\n        cached_data = pickle.load(f)\n        topic_words = cached_data['topic_words']\n        tokens = cached_data['tokens']\n        corpus = cached_data['corpus']\n        dictionary = cached_data['dictionary']\n    \n    print(f\"Computing coherence score...\")\n    coherence_model = CoherenceModel(topics=topic_words, \n                                 texts=tokens, \n                                 corpus=corpus,\n                                 dictionary=dictionary, \n                                 coherence='c_v')\n    coherence = coherence_model.get_coherence()\n    print(f\"Coherence score for model {model_no}: {coherence}\")\n    \n    return coherence","metadata":{"execution":{"iopub.status.busy":"2022-10-28T05:33:33.518504Z","iopub.execute_input":"2022-10-28T05:33:33.518893Z","iopub.status.idle":"2022-10-28T05:33:33.527768Z","shell.execute_reply.started":"2022-10-28T05:33:33.518866Z","shell.execute_reply":"2022-10-28T05:33:33.525369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coherences = [evaluate_coherence_scores(model) for model in models]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T04:59:46.541209Z","iopub.execute_input":"2022-10-28T04:59:46.541578Z","iopub.status.idle":"2022-10-28T05:28:11.761408Z","shell.execute_reply.started":"2022-10-28T04:59:46.541553Z","shell.execute_reply":"2022-10-28T05:28:11.759582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bad_models = [\n    \"10-lemmatized-BERTopic-ipca90-batchkmean300-8N\",\n    \"7-lemmatized-BERTopic-ipca75-batchkmean250-8N\",\n    \"8-lemmatized-BERTopic-ipca225-batchkmean350-8N\",\n]\n\nbad_model_coherences = [evaluate_coherence_scores(model) for model in bad_models]","metadata":{"execution":{"iopub.status.busy":"2022-10-28T05:33:35.770685Z","iopub.execute_input":"2022-10-28T05:33:35.771047Z","iopub.status.idle":"2022-10-28T05:46:33.791992Z","shell.execute_reply.started":"2022-10-28T05:33:35.771020Z","shell.execute_reply":"2022-10-28T05:46:33.790126Z"},"trusted":true},"execution_count":null,"outputs":[]}]}